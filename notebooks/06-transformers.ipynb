{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25e4e7d3",
   "metadata": {},
   "source": [
    "# Lesson 5: Transformers\n",
    "\n",
    "*Teachers:* Fares Schulz, Lina Campanella\n",
    "\n",
    "In this course we will cover:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb36e8f",
   "metadata": {},
   "source": [
    "## Bach Chorale Generation with Transformers\n",
    "\n",
    "Now let's train our Transformer on Bach chorales and compare it with the RNN approach. We'll use the same JSB Chorales dataset but leverage the Transformer's attention mechanism for better long-range dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9bd863ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists at resources/_data/jsb_chorales/jsb_chorales.tar\n",
      "Extracting resources/_data/jsb_chorales/jsb_chorales.tar\n",
      "Extracted to resources/_data/jsb_chorales\n",
      "Dataset available at: resources/_data/jsb_chorales/jsb_chorales.tar\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import tarfile\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Download the dataset using urllib and extract with tarfile\n",
    "download_link = \"https://github.com/iCorv/jsb-chorales-dataset/raw/main/jsb_chorales.tar\"\n",
    "data_dir = Path('resources/_data/jsb_chorales')\n",
    "tar_path = data_dir / 'jsb_chorales.tar'\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Download the file if it doesn't already exist\n",
    "if not tar_path.exists():\n",
    "    print(f\"Downloading dataset from {download_link}\")\n",
    "    urllib.request.urlretrieve(download_link, tar_path)\n",
    "    print(f\"Downloaded to {tar_path}\")\n",
    "else:\n",
    "    print(f\"Dataset already exists at {tar_path}\")\n",
    "\n",
    "# Extract the tar file\n",
    "if tar_path.exists() and not (data_dir / 'jsb_chorales').exists():\n",
    "    print(f\"Extracting {tar_path}\")\n",
    "    with tarfile.open(tar_path, 'r') as tar:\n",
    "        tar.extractall(path=data_dir)\n",
    "    print(f\"Extracted to {data_dir}\")\n",
    "\n",
    "filepath = str(tar_path)\n",
    "print(f\"Dataset available at: {filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "829c5bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "jsb_chorales_dir = Path(filepath).parent\n",
    "train_files = sorted(jsb_chorales_dir.glob(\"train/chorale_*.csv\"))\n",
    "valid_files = sorted(jsb_chorales_dir.glob(\"valid/chorale_*.csv\"))\n",
    "test_files = sorted(jsb_chorales_dir.glob(\"test/chorale_*.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "300fb7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_chorales(filepaths):\n",
    "    return [pd.read_csv(filepath).values.tolist() for filepath in filepaths]\n",
    "\n",
    "train_chorales = load_chorales(train_files)\n",
    "valid_chorales = load_chorales(valid_files)\n",
    "test_chorales = load_chorales(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "db23169a",
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = set()\n",
    "for chorales in (train_chorales, valid_chorales, test_chorales):\n",
    "    for chorale in chorales:\n",
    "        for chord in chorale:\n",
    "            notes |= set(chord)\n",
    "\n",
    "n_notes = len(notes)\n",
    "min_note = min(notes - {0})\n",
    "max_note = max(notes)\n",
    "\n",
    "assert min_note == 36\n",
    "assert max_note == 81"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1135b92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from resources._code.synthesizer import SimpleSynth\n",
    "\n",
    "baroque_synth = SimpleSynth(tempo=160, amplitude=0.1, sample_rate=44100, baroque_tuning=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9cca8119",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "def preprocess(window):\n",
    "    # Shift values: keep 0 as 0 (silence), shift other notes to start from 1\n",
    "    window = torch.where(window == 0, window, window - min_note + 1)\n",
    "    return window.reshape(-1)  # convert to arpeggio (flatten to 1D sequence)\n",
    "\n",
    "class BachDataset(Dataset):\n",
    "    def __init__(self, chorales, window_size=32, window_shift=16):\n",
    "        self.chorales = chorales\n",
    "        self.window_size = window_size\n",
    "        self.window_shift = window_shift\n",
    "        self.windows = self._create_windows()\n",
    "    \n",
    "    def _create_windows(self):\n",
    "        windows = []\n",
    "        for chorale in self.chorales:\n",
    "            chorale_tensor = torch.tensor(chorale, dtype=torch.long)\n",
    "            \n",
    "            # Create sliding windows\n",
    "            for i in range(0, len(chorale) - self.window_size, self.window_shift):\n",
    "                window = chorale_tensor[i:i + self.window_size + 1]\n",
    "                if len(window) == self.window_size + 1:  # Ensure full window\n",
    "                    windows.append(window)\n",
    "        \n",
    "        return windows\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.windows)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        window = self.windows[idx]\n",
    "        # Preprocess: shift note values and flatten\n",
    "        preprocessed = preprocess(window)\n",
    "        \n",
    "        # Create input/target pairs \n",
    "        X = preprocessed[:-1]\n",
    "        Y = preprocessed[1:] # predict next note in each arpegio, at each step\n",
    "        \n",
    "        return X, Y\n",
    "\n",
    "def bach_dataloader(chorales, batch_size=32, shuffle=False, window_size=32, window_shift=16):\n",
    "    \n",
    "    dataset = BachDataset(chorales, window_size, window_shift)\n",
    "    \n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    \n",
    "    return dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1995c10",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[64]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# load the datasets\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m train_set = \u001b[43mbach_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_chorales\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m valid_set = bach_dataloader(valid_chorales)\n\u001b[32m      4\u001b[39m test_set = bach_dataloader(test_chorales)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[63]\u001b[39m\u001b[32m, line 45\u001b[39m, in \u001b[36mbach_dataloader\u001b[39m\u001b[34m(chorales, batch_size, shuffle, window_size, window_shift)\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbach_dataloader\u001b[39m(chorales, batch_size=\u001b[32m32\u001b[39m, shuffle=\u001b[38;5;28;01mFalse\u001b[39;00m, window_size=\u001b[32m32\u001b[39m, window_shift=\u001b[32m16\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m     dataset = \u001b[43mBachDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchorales\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow_shift\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m     dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n\u001b[32m     49\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m dataloader\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[63]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mBachDataset.__init__\u001b[39m\u001b[34m(self, chorales, window_size, window_shift)\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mself\u001b[39m.window_size = window_size\n\u001b[32m     13\u001b[39m \u001b[38;5;28mself\u001b[39m.window_shift = window_shift\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28mself\u001b[39m.windows = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_windows\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[63]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mBachDataset._create_windows\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     17\u001b[39m windows = []\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m chorale \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.chorales:\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     chorale_tensor = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchorale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlong\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m     \u001b[38;5;66;03m# Create sliding windows\u001b[39;00m\n\u001b[32m     22\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(chorale) - \u001b[38;5;28mself\u001b[39m.window_size, \u001b[38;5;28mself\u001b[39m.window_shift):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# load the datasets\n",
    "train_set = bach_dataloader(train_chorales, shuffle=True)\n",
    "valid_set = bach_dataloader(valid_chorales)\n",
    "test_set = bach_dataloader(test_chorales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c359832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model=256, num_heads=4):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_model // num_heads\n",
    "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
    "\n",
    "        self.Wv = nn.Linear(d_model, d_model, bias=False) # the Value parameters\n",
    "        self.Wk = nn.Linear(d_model, d_model, bias=False) # the Key parameters\n",
    "        self.Wq = nn.Linear(d_model, d_model, bias=False) # the Query parameters\n",
    "        self.Wo = nn.Linear(d_model, d_model, bias=False) # the output parameters\n",
    "\n",
    "\n",
    "    def scaled_dot_product_attention(self, query, key, value, attention_mask=None, key_padding_mask=None):        \n",
    "        d_k = query.size(-1)\n",
    "        tgt_len, src_len = query.size(-2), key.size(-2)\n",
    "\n",
    "        # logits = query * key^T / sqrt(d_k)\n",
    "        logits = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k) \n",
    "\n",
    "        # Attention mask here\n",
    "        if attention_mask is not None:\n",
    "            if attention_mask.dim() == 2:\n",
    "                assert attention_mask.size() == (tgt_len, src_len)\n",
    "                attention_mask = attention_mask.unsqueeze(0)\n",
    "                logits = logits + attention_mask\n",
    "            else:\n",
    "                raise ValueError(f\"Attention mask size {attention_mask.size()}\")\n",
    "                \n",
    "        # Key mask here\n",
    "        if key_padding_mask is not None:\n",
    "            key_padding_mask = key_padding_mask.unsqueeze(1).unsqueeze(2) # Broadcast over batch size, num heads\n",
    "            logits = logits + key_padding_mask\n",
    "        \n",
    "        attention = torch.softmax(logits, dim=-1)\n",
    "        output = torch.matmul(attention, value) # (batch_size, num_heads, sequence_length, head_dim)\n",
    "        \n",
    "        return output, attention\n",
    "\n",
    "    \n",
    "    def split_into_heads(self, x):\n",
    "        batch_size, seq_length, _ = x.size()\n",
    "        x = x.view(batch_size, seq_length, self.num_heads, self.head_dim)\n",
    "        return x.transpose(1, 2) # Final dim will be (batch_size, num_heads, seq_length, head_dim)\n",
    "\n",
    "    def combine_heads(self, x):\n",
    "        batch_size, _, seq_length, _ = x.size()\n",
    "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_model)\n",
    "        \n",
    "    \n",
    "    def forward(self, q, k, v, attention_mask=None, key_padding_mask=None):\n",
    "   \n",
    "        q = self.Wq(q) # (batch_size, query_sequence_length, d_model)\n",
    "        k = self.Wk(k) # (batch_size, key_sequence_length, d_model)\n",
    "        v = self.Wv(v) # (batch_size, key_sequence_length, d_model)\n",
    "\n",
    "        q = self.split_into_heads(q)\n",
    "        k = self.split_into_heads(k)\n",
    "        v = self.split_into_heads(v)\n",
    "        \n",
    "        attention_values, attention_weights  = self.scaled_dot_product_attention(query=q, key=k, value=v, attention_mask=attention_mask, key_padding_mask=key_padding_mask)\n",
    "        grouped = self.combine_heads(attention_values)\n",
    "        output = self.Wo(grouped)\n",
    "        \n",
    "        self.attention_weights = attention_weights\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ef5ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        \n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, :x.size(1), :]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020a49ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, hidden_dim=None):\n",
    "        super().__init__()\n",
    "        if hidden_dim is None:\n",
    "            hidden_dim = 4 * d_model  # Standard 4x expansion\n",
    "        self.fc1 = nn.Linear(d_model, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "\n",
    "    def forward(self, x):        \n",
    "        return self.fc2(self.relu(self.fc1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b5744af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, d_model, dropout, num_heads):\n",
    "        super().__init__()\n",
    "        \n",
    "        # The first Multi-Head Attention has a mask to avoid looking at the future\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.self_attention = MultiHeadAttention(d_model=d_model, num_heads=num_heads)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.ff = PositionWiseFeedForward(d_model)\n",
    "        \n",
    "        # Add proper dropout layers\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout) \n",
    "        \n",
    "        \n",
    "    def forward(self, tgt, tgt_mask=None, tgt_padding_mask=None):\n",
    "        masked_att_output = self.self_attention(q=self.norm1(tgt), k=self.norm1(tgt), v=self.norm1(tgt), attention_mask=tgt_mask, key_padding_mask=tgt_padding_mask)\n",
    "        x = tgt + self.dropout1(masked_att_output)\n",
    "        \n",
    "        ff_output = self.ff(self.norm2(x))\n",
    "        output = x + self.dropout2(ff_output)\n",
    "\n",
    "        return output\n",
    "    \n",
    "\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, d_model, dropout, num_decoder_blocks, num_heads, shared_embedding):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.embedding = shared_embedding\n",
    "        self.positional_encoding = PositionalEncoding(d_model=d_model, dropout=dropout)\n",
    "          \n",
    "        self.decoder_blocks = nn.ModuleList([DecoderBlock(d_model, dropout, num_heads) for _ in range(num_decoder_blocks)])\n",
    "        \n",
    "        \n",
    "    def forward(self, tgt, tgt_mask=None, tgt_padding_mask=None):\n",
    "        x = self.embedding(tgt) #* math.sqrt(self.d_model)\n",
    "        x = self.positional_encoding(x)\n",
    "\n",
    "        for block in self.decoder_blocks:\n",
    "            x = block(x, tgt_mask=tgt_mask, tgt_padding_mask=tgt_padding_mask)\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbc0f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        \n",
    "        for k, v in kwargs.items():\n",
    "            print(f\" * {k}={v}\")\n",
    "        \n",
    "        self.n_notes = kwargs.get('n_notes')\n",
    "        self.d_model = kwargs.get('d_model', kwargs.get('model_dim'))  # Support both names\n",
    "        self.dropout = kwargs.get('dropout')\n",
    "        self.n_decoder_layers = kwargs.get('n_decoder_layers')\n",
    "        self.n_heads = kwargs.get('n_heads')\n",
    "        self.batch_size = kwargs.get('batch_size')\n",
    "\n",
    "        self.shared_embedding = nn.Embedding(self.n_notes, self.d_model)\n",
    "\n",
    "        self.decoder = Decoder(self.d_model, self.dropout, self.n_decoder_layers, self.n_heads, self.shared_embedding)\n",
    "        self.fc = nn.Linear(self.d_model, self.n_notes)\n",
    "        self.fc.weight = self.shared_embedding.weight  # Weight sharing!\n",
    "\n",
    "        \n",
    "\n",
    "    @staticmethod    \n",
    "    def generate_square_subsequent_mask(size, device=None):\n",
    "            mask = (1 - torch.triu(torch.ones(size, size, device=device), diagonal=1)).bool()\n",
    "            mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "            return mask\n",
    "\n",
    "    \n",
    "    # def decode(self, tgt) -> torch.Tensor:    \n",
    "    #     decoder_output = self.decoder(tgt=tgt, tgt_mask=self.generate_square_subsequent_mask(tgt.size(1), device=tgt.device))  \n",
    "    #     # output = self.fc(decoder_output)  # shape (B, L, C)\n",
    "    #     return decoder_output\n",
    "\n",
    "        \n",
    "        \n",
    "    def forward(self, x ) -> torch.Tensor:\n",
    "        # Manually apply embeddings\n",
    "        # x_embedded = self.shared_embedding(x) * math.sqrt(self.d_model)\n",
    "        # y_embedded = self.shared_embedding(y)  # No scaling for decoder\n",
    "        tgt_mask = self.generate_square_subsequent_mask(x.size(1), device=x.device)\n",
    "        # Decoder output shape (B, L, C)\n",
    "        decoder_output = self.decoder(tgt=x, tgt_mask=tgt_mask)  \n",
    "        output = self.fc(decoder_output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9933fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_idx, (src, tgt) in enumerate(train_loader): \n",
    "        src, tgt = src.to(device), tgt.to(device)\n",
    "       \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass: encoder gets source, decoder gets shifted target\n",
    "        outputs = model(src)\n",
    "        \n",
    "        # Reshape for cross entropy loss\n",
    "        outputs_flat = outputs.reshape(-1, outputs.size(-1))\n",
    "        tgt_flat = tgt.reshape(-1)\n",
    "        \n",
    "        loss = criterion(outputs_flat, tgt_flat)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()        \n",
    " \n",
    "        # Calculate accuracy\n",
    "        _, predicted = outputs_flat.max(dim=1)\n",
    "        total += tgt_flat.size(0)\n",
    "        correct += predicted.eq(tgt_flat).sum().item()\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    accuracy = 100. * correct / total\n",
    "    \n",
    "    return avg_loss, accuracy\n",
    "\n",
    "def validate(model, valid_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (src, tgt) in enumerate(valid_loader):  \n",
    "            src, tgt = src.to(device), tgt.to(device)\n",
    "            \n",
    "            # Forward pass: encoder gets source, decoder gets shifted target\n",
    "            outputs = model(src)\n",
    "            \n",
    "            # Reshape for cross entropy loss\n",
    "            outputs_flat = outputs.reshape(-1, outputs.size(-1))\n",
    "            tgt_flat = tgt.reshape(-1)\n",
    "            \n",
    "            loss = criterion(outputs_flat, tgt_flat)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            _, predicted = outputs_flat.max(1)\n",
    "            total += tgt_flat.size(0)\n",
    "            correct += predicted.eq(tgt_flat).sum().item()\n",
    "        \n",
    "        avg_loss = total_loss / len(valid_loader)\n",
    "        accuracy = 100. * correct / total\n",
    "    \n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74ca3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Training loop \n",
    "def train_model(model, train_loader, valid_loader, optimizer, criterion, epochs=15, device='cpu'):\n",
    "    print(\"Starting training...\")\n",
    "    \n",
    "    # Use local lists to avoid duplication\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # Validation\n",
    "        val_loss, val_acc = validate(model, valid_loader, criterion, device)\n",
    "        valid_losses.append(val_loss)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{epochs}:')\n",
    "        print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
    "        print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
    "        print('-' * 50)\n",
    "\n",
    "    print(\"Training completed!\")\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(range(epochs), train_losses, label='Train Loss')\n",
    "    plt.plot(range(epochs), valid_losses, label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "26cd376a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * n_notes=47\n",
      " * d_model=256\n",
      " * dropout=0.1\n",
      " * n_decoder_layers=4\n",
      " * n_heads=8\n",
      " * batch_size=32\n",
      "Model initialized with 3167023 parameters\n",
      "Training on device: mps\n",
      "Starting training...\n",
      "Epoch 1/15:\n",
      "Train Loss: 14.6050, Train Acc: 26.21%\n",
      "Val Loss: 2.2487, Val Acc: 52.61%\n",
      "--------------------------------------------------\n",
      "Epoch 2/15:\n",
      "Train Loss: 2.0011, Train Acc: 57.47%\n",
      "Val Loss: 1.3477, Val Acc: 70.87%\n",
      "--------------------------------------------------\n",
      "Epoch 3/15:\n",
      "Train Loss: 1.3614, Train Acc: 68.10%\n",
      "Val Loss: 1.0455, Val Acc: 75.26%\n",
      "--------------------------------------------------\n",
      "Epoch 4/15:\n",
      "Train Loss: 1.1001, Train Acc: 72.40%\n",
      "Val Loss: 1.0156, Val Acc: 75.32%\n",
      "--------------------------------------------------\n",
      "Epoch 5/15:\n",
      "Train Loss: 0.9790, Train Acc: 74.54%\n",
      "Val Loss: 0.8609, Val Acc: 78.38%\n",
      "--------------------------------------------------\n",
      "Epoch 6/15:\n",
      "Train Loss: 0.8608, Train Acc: 76.75%\n",
      "Val Loss: 0.8516, Val Acc: 77.98%\n",
      "--------------------------------------------------\n",
      "Epoch 7/15:\n",
      "Train Loss: 0.7769, Train Acc: 78.48%\n",
      "Val Loss: 0.7626, Val Acc: 80.46%\n",
      "--------------------------------------------------\n",
      "Epoch 8/15:\n",
      "Train Loss: 0.7063, Train Acc: 79.92%\n",
      "Val Loss: 0.7511, Val Acc: 80.42%\n",
      "--------------------------------------------------\n",
      "Epoch 9/15:\n",
      "Train Loss: 0.6770, Train Acc: 80.77%\n",
      "Val Loss: 0.7296, Val Acc: 80.76%\n",
      "--------------------------------------------------\n",
      "Epoch 10/15:\n",
      "Train Loss: 0.6323, Train Acc: 81.64%\n",
      "Val Loss: 0.6740, Val Acc: 82.02%\n",
      "--------------------------------------------------\n",
      "Epoch 11/15:\n",
      "Train Loss: 0.6026, Train Acc: 82.30%\n",
      "Val Loss: 0.6880, Val Acc: 81.72%\n",
      "--------------------------------------------------\n",
      "Epoch 12/15:\n",
      "Train Loss: 0.5725, Train Acc: 83.02%\n",
      "Val Loss: 0.6783, Val Acc: 82.02%\n",
      "--------------------------------------------------\n",
      "Epoch 13/15:\n",
      "Train Loss: 0.5504, Train Acc: 83.51%\n",
      "Val Loss: 0.7258, Val Acc: 81.17%\n",
      "--------------------------------------------------\n",
      "Epoch 14/15:\n",
      "Train Loss: 0.5312, Train Acc: 83.98%\n",
      "Val Loss: 0.7038, Val Acc: 81.94%\n",
      "--------------------------------------------------\n",
      "Epoch 15/15:\n",
      "Train Loss: 0.5114, Train Acc: 84.49%\n",
      "Val Loss: 0.7152, Val Acc: 82.17%\n",
      "--------------------------------------------------\n",
      "Training completed!\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize the Transformer model\n",
    "config = {\n",
    "    'n_notes': 47,\n",
    "    'd_model': 256, \n",
    "    'dropout': 0.1,\n",
    "    'n_decoder_layers': 4,\n",
    "    'n_heads': 8,\n",
    "    'batch_size': 32\n",
    "}\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 15\n",
    "\n",
    "model = Transformer(**config)\n",
    "# device = torch.device('cpu')\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "model = model.to(device)  # Fixed: uncommented this line\n",
    "\n",
    "print(f\"Model initialized with {sum(p.numel() for p in model.parameters())} parameters\")\n",
    "print(f\"Training on device: {device}\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "   \n",
    "# Run training\n",
    "train_model(model=model, train_loader=train_set, valid_loader=valid_set,  optimizer=optimizer, criterion=criterion, epochs=num_epochs, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73020c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (src, tgt) in enumerate(test_loader): \n",
    "            src, tgt = src.to(device), tgt.to(device)\n",
    "            \n",
    "            # Forward pass: encoder gets source, decoder gets shifted target\n",
    "            outputs = model(src)\n",
    "            \n",
    "            # Reshape for cross entropy loss\n",
    "            outputs_flat = outputs.reshape(-1, outputs.size(-1))\n",
    "            tgt_flat = tgt.reshape(-1)\n",
    "            \n",
    "            loss = criterion(outputs_flat, tgt_flat)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            _, predicted = outputs_flat.max(1)\n",
    "            total += tgt_flat.size(0)\n",
    "            correct += predicted.eq(tgt_flat).sum().item()\n",
    "        \n",
    "        avg_loss = total_loss / len(test_loader)\n",
    "        accuracy = 100. * correct / total\n",
    "    \n",
    "        print(f'Test Results:')\n",
    "        print(f'Test Loss: {avg_loss:.4f}')\n",
    "        print(f'Test Accuracy: {accuracy:.2f}%')\n",
    "        \n",
    "    return avg_loss, accuracy\n",
    "\n",
    "    \n",
    "# Evaluate the model on test set\n",
    "test_loss, test_acc = evaluate_model(model, test_set, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd034d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_chorale(model, seed_chords, length=32):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient computation for inference\n",
    "        # Convert seed chords to tensor and preprocess\n",
    "        seed_tensor = torch.tensor(seed_chords, dtype=torch.long)\n",
    "        arpegio = preprocess(seed_tensor)\n",
    "        arpegio = arpegio.unsqueeze(0).to(device)  # Add batch dimension and move to device\n",
    "        \n",
    "        # Generate new notes\n",
    "        for chord in range(length):\n",
    "            for note in range(4):\n",
    "            \n",
    "                # Get model prediction for the current sequence\n",
    "                outputs = model(arpegio)  # Shape: (1, seq_len, n_notes)\n",
    "                \n",
    "                # Get the prediction for the last timestep\n",
    "                last_output = outputs[0, -1, :]  # Shape: (n_notes,)\n",
    "                \n",
    "                # Get the most likely next note\n",
    "                next_note = torch.argmax(last_output, dim=-1, keepdim=True)  # Shape: (1,)\n",
    "                \n",
    "                # Append the predicted note to the sequence\n",
    "                arpegio = torch.cat([arpegio, next_note.unsqueeze(0)], dim=1)\n",
    "\n",
    "        # Convert back to original note range (reverse the preprocessing)\n",
    "        arpegio = torch.where(arpegio == 0, arpegio, arpegio + min_note - 1)\n",
    "        \n",
    "        # Reshape to chord format (group every 4 notes)\n",
    "        arpegio_flat = arpegio.squeeze(0)  # Remove batch dimension\n",
    "        n_total_notes = len(arpegio_flat)\n",
    "        n_complete_chords = n_total_notes // 4\n",
    "        \n",
    "        # Take only complete chords and reshape\n",
    "        chorale = arpegio_flat[:n_complete_chords * 4].reshape(-1, 4)\n",
    "        \n",
    "        return chorale.cpu().numpy()  # Convert back to numpy for compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afddb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_chords = test_chorales[2][:12]\n",
    "baroque_synth.play_chorale(seed_chords)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ed9db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_chorale = generate_chorale(model, seed_chords, length=32)\n",
    "baroque_synth.play_chorale(new_chorale)\n",
    "print(\"Generated Chorale:\")\n",
    "print(new_chorale[12:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7ce91d",
   "metadata": {},
   "source": [
    "## Analyzing Transformer vs RNN Performance\n",
    "\n",
    "### Key Differences to Highlight:\n",
    "\n",
    "1. **Attention Mechanism**: \n",
    "   - Transformer can attend to any position in the sequence simultaneously\n",
    "   - RNN processes sequentially, potentially losing long-term dependencies\n",
    "\n",
    "2. **Parallelization**: \n",
    "   - Transformer training can be parallelized (all positions at once)\n",
    "   - RNN training is inherently sequential\n",
    "\n",
    "3. **Musical Structure**:\n",
    "   - Transformer might better capture harmonic relationships across time\n",
    "   - Can potentially learn chord progressions and voice leading patterns\n",
    "\n",
    "4. **Generation Quality**:\n",
    "   - Compare coherence of generated chorales\n",
    "   - Look at harmonic consistency and voice independence\n",
    "\n",
    "### Exercises for Students:\n",
    "\n",
    "1. **Experiment with attention heads**: Try different numbers of attention heads and see how it affects generation quality\n",
    "\n",
    "2. **Temperature sampling**: Adjust the temperature parameter to control randomness vs structure\n",
    "\n",
    "3. **Seed analysis**: Try different seed sequences and observe how the model continues them\n",
    "\n",
    "4. **Attention visualization**: Plot attention weights to see what the model focuses on (advanced)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".dlad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
